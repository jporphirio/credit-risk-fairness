{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocolo de Modelagem\n",
    "\n",
    "## Objetivo do Notebook\n",
    "Ajustar um protocolo que teste modelos lineares e não lineares com diferentes estratégias de oversampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, Perceptron\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    ")\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    count,\n",
    "    demographic_parity_difference,\n",
    "    demographic_parity_ratio,\n",
    "    equalized_odds_difference,\n",
    "    equalized_odds_ratio,\n",
    "    equal_opportunity_difference,\n",
    "    equal_opportunity_ratio,\n",
    "    false_positive_rate_difference,\n",
    "    false_positive_rate_ratio,\n",
    "    false_negative_rate_difference,\n",
    "    false_negative_rate_ratio,\n",
    "    selection_rate\n",
    ")\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import os\n",
    "import time\n",
    "seed = 19\n",
    "\n",
    "# Definir caminho para a pasta de resultados\n",
    "results_path = \"../datasets/results\"\n",
    "\n",
    "# Função para carregar datasets a partir da pasta\n",
    "def carregar_dataset(caminho_csv):\n",
    "    return pd.read_csv(caminho_csv)\n",
    "\n",
    "# Função para configurar o pré-processador automaticamente\n",
    "def configurar_preprocessador(x):\n",
    "    categorical_features = x.select_dtypes(include=['object','category']).columns.tolist()\n",
    "    numerical_features = x.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # Identificar variáveis ordinais automaticamente (começam com \"ordinal_\")\n",
    "    ordinal_features = [col for col in numerical_features if col.startswith(\"ordinal_\")]\n",
    "\n",
    "    # Excluir variáveis ordinais das variáveis numéricas contínuas\n",
    "    numerical_continuous_features = [col for col in numerical_features if col not in ordinal_features]\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_continuous_features),  # Escalar apenas variáveis contínuas\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features),  # One-Hot Encoding para categóricas\n",
    "            ('ord', 'passthrough', ordinal_features)  # Manter variáveis ordinais sem transformação\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def treinar_e_ajustar_modelos_por_sensivel(x_train, y_train, grupo_focus_train, models, cv, smote_config, smote_label, label, arquivo):\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    resultados = []\n",
    "    pipelines = {}\n",
    "\n",
    "    print(f\"\\nIniciando treino com oversampling pelo GRUPO_FOCUS | Cenário: {label} | Método: {smote_label}\")\n",
    "    print(f\"Antes do oversampling - x_train shape: {x_train.shape}\")\n",
    "\n",
    "    # Se houver oversampling, criamos a base estendida com target\n",
    "    if smote_config is not None:\n",
    "        df_balance = x_train.copy()\n",
    "        df_balance[\"grupo_focus\"] = grupo_focus_train\n",
    "        df_balance[\"target\"] = y_train\n",
    "\n",
    "        X = df_balance.drop(columns=[\"grupo_focus\"])\n",
    "        y = df_balance[\"grupo_focus\"]\n",
    "\n",
    "        categorical_features_idx = [\n",
    "            i for i, col in enumerate(X.columns)\n",
    "            if X[col].dtype == 'object' or X[col].dtype == 'category' or col == 'target'\n",
    "        ]\n",
    "\n",
    "        method = smote_config.pop(\"method\", \"smotenc\")  # default\n",
    "\n",
    "        if method == \"random\":\n",
    "            from imblearn.over_sampling import RandomOverSampler\n",
    "            sampler = RandomOverSampler(sampling_strategy=smote_config.get(\"sampling_strategy\", 'auto'), random_state=seed)\n",
    "\n",
    "        elif method == \"smote_tomek\":\n",
    "            from imblearn.combine import SMOTETomek\n",
    "            smote = SMOTENC(categorical_features=categorical_features_idx, random_state=seed)\n",
    "            sampler = SMOTETomek(smote=smote, sampling_strategy=smote_config.get(\"sampling_strategy\", 'auto'))\n",
    "\n",
    "        elif method == \"smote_enn\":\n",
    "            from imblearn.combine import SMOTEENN\n",
    "            smote = SMOTENC(categorical_features=categorical_features_idx, random_state=seed)\n",
    "            sampler = SMOTEENN(smote=smote, sampling_strategy=smote_config.get(\"sampling_strategy\", 'auto'))\n",
    "\n",
    "        else:  # padrão: SMOTENC\n",
    "            from imblearn.over_sampling import SMOTENC\n",
    "            sampler = SMOTENC(categorical_features=categorical_features_idx, random_state=seed, **smote_config)\n",
    "  \n",
    "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "\n",
    "        target_resampled = X_resampled[\"target\"]\n",
    "        X_resampled = X_resampled.drop(columns=[\"target\"])\n",
    "        #X_resampled[\"grupo_focus\"] = y_resampled\n",
    "    else:\n",
    "        # Sem oversampling, usar os dados originais\n",
    "        X_resampled = x_train.copy()\n",
    "        target_resampled = y_train.copy()\n",
    "\n",
    "    print(f\"Após oversampling - X shape: {X_resampled.shape}\")\n",
    "\n",
    "    # Salvar a base de treino com target e sensitive\n",
    "    df_train = X_resampled.copy()\n",
    "    df_train[\"target\"] = target_resampled\n",
    "    base_filename = f\"{arquivo}_{smote_label}_{label.replace(' ', '_')}_train_base_balance_GRUPO_FOCUS.csv\"\n",
    "    df_train.to_csv(os.path.join(results_path, base_filename), index=False)\n",
    "\n",
    "    # Aplicar pré-processamento fora da pipeline apenas para ver o que vai acontecer com o dataset\n",
    "    # etapa redundante pois o pre processamento 'oficial' esta sendo utilizado dentro da pipeline\n",
    "    print(\"Aplicando pré-processamento nos dados de treino\")\n",
    "    preprocessor = configurar_preprocessador(X_resampled)\n",
    "    X_transf = preprocessor.fit_transform(X_resampled)\n",
    "    print(f\"Shape após pré-processamento: {X_transf.shape}\")\n",
    "\n",
    "    # Treinar modelos\n",
    "    for nome, config in models.items():\n",
    "        print(f\"Fit do modelo: {nome}\", \"início:\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        steps = [\n",
    "            ('preprocessor', preprocessor), #todo dataset q entrar aqui sofrera o preprocessamento\n",
    "            ('classifier', config['model'])\n",
    "        ]\n",
    "        pipeline = ImbPipeline(steps=steps)\n",
    "        grid_search = GridSearchCV(pipeline, param_grid=config['params'], cv=cv, scoring='f1_macro')\n",
    "        grid_search.fit(X_resampled, target_resampled)\n",
    "\n",
    "        pipelines[nome] = grid_search.best_estimator_\n",
    "        resultados.append({\n",
    "            \"modelo\": nome,\n",
    "            \"smote\": smote_label,\n",
    "            \"cenario\": label,\n",
    "            \"melhor_f1\": grid_search.best_score_,\n",
    "            \"melhores_parametros\": grid_search.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultados), pipelines\n",
    "\n",
    "\n",
    "# NOVA Função para calcular a importância das variáveis usando permutação\n",
    "def calcular_importancia_variaveis(pipeline, modelo, arquivo, label, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Calcula a importância das variáveis via permutação.\n",
    "    \n",
    "    Parâmetros:\n",
    "        - pipeline: pipeline treinado (com preprocessor + modelo)\n",
    "        - modelo: nome do modelo (str)\n",
    "        - arquivo: nome do dataset (str)\n",
    "        - label: cenário (str)\n",
    "        - X_val: base de validação original (sem pré-processar)\n",
    "        - y_val: target de validação\n",
    "    Retorna:\n",
    "        - Lista de dicionários com importâncias\n",
    "    \"\"\"\n",
    "    preprocessor = pipeline.named_steps['preprocessor']\n",
    "    classifier = pipeline.named_steps['classifier']\n",
    "\n",
    "    # Aplicar o pré-processamento no conjunto de validação\n",
    "    X_val_transf = preprocessor.transform(X_val)\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "    # Importância por permutação\n",
    "    result = permutation_importance(\n",
    "        classifier,\n",
    "        X_val_transf,\n",
    "        y_val,\n",
    "        n_repeats=10,\n",
    "        random_state=seed,\n",
    "        scoring='f1_macro'\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"dataset\": arquivo,\n",
    "            \"cenario\": label,\n",
    "            \"modelo\": modelo,\n",
    "            \"variavel\": name,\n",
    "            \"importancia\": importance\n",
    "        }\n",
    "        for name, importance in zip(feature_names, result.importances_mean)\n",
    "    ]\n",
    "\n",
    "# Funções para calcular taxas baseadas na matriz de confusão\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    return tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "\n",
    "def true_negative_rate(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    return tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "\n",
    "def false_positive_rate(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    return fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
    "\n",
    "def false_negative_rate(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    return fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
    "\n",
    "# Função para calcular métricas de fairness extras (agrupadas)\n",
    "def extended_fairness(y_true, y_pred, sensitive_features):\n",
    "    extended_fairness_metrics = {\n",
    "        \"demographic_parity_difference\": demographic_parity_difference(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"demographic_parity_ratio\": demographic_parity_ratio(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"equalized_odds_difference\": equalized_odds_difference(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"equalized_odds_ratio\": equalized_odds_ratio(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"equal_opportunity_difference\": equal_opportunity_difference(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"equal_opportunity_ratio\": equal_opportunity_ratio(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"false_positive_rate_difference\": false_positive_rate_difference(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"false_positive_rate_ratio\": false_positive_rate_ratio(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"false_negative_rate_difference\": false_negative_rate_difference(y_true, y_pred, sensitive_features=sensitive_features),\n",
    "        \"false_negative_rate_ratio\": false_negative_rate_ratio(y_true, y_pred, sensitive_features=sensitive_features)\n",
    "    }\n",
    "    return extended_fairness_metrics\n",
    "\n",
    "# Lista de cenários de SMOTE\n",
    "smote_cenarios = [\n",
    "    {\"label\": \"Original\", \"config\": None},\n",
    "    {\"label\": \"SMOTE_expand_5x\", \"config\": {\"sampling_strategy\": {1: 5000}, \"k_neighbors\": 3}},\n",
    "    {\"label\": \"SMOTE_default\", \"config\": {}},\n",
    "    {\"label\": \"RandomOverSampler\", \"config\": {\"method\": \"random\"}},\n",
    "]\n",
    "\n",
    "# Função principal para rodar o protocolo com comparação de cenários\n",
    "def executar_protocolo_com_cenarios(caminho_pasta):\n",
    "    arquivos = [f for f in os.listdir(caminho_pasta) if f.endswith('.csv')]\n",
    "    models = {\n",
    "        'Logistic Regression': {\n",
    "        'model': LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000, random_state=seed),\n",
    "        'params': {'classifier__C': [1.0]}  # Apenas para compatibilidade com GridSearch\n",
    "    },\n",
    "    'Ridge (L2)': {\n",
    "        'model': LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000, random_state=seed),\n",
    "        'params': {'classifier__C': [0.1, 1, 10]}  # Inverso da regularização\n",
    "    },\n",
    "    'Lasso (L1)': {\n",
    "        'model': LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000, random_state=seed),\n",
    "        'params': {'classifier__C': [0.1, 1, 10]}\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'model': LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000, random_state=seed),\n",
    "        'params': {\n",
    "            'classifier__C': [0.1, 1, 10],\n",
    "            'classifier__l1_ratio': [0.2, 0.5, 0.8]\n",
    "        }\n",
    "    },\n",
    "    'SGDClassifier (Logistic)': {\n",
    "        'model': SGDClassifier(loss='log_loss', penalty='l2', max_iter=1000, random_state=seed),\n",
    "        'params': {'classifier__alpha': [0.0001, 0.001, 0.01]}  # alpha = 1/C\n",
    "    },\n",
    "    'Single Layer Perceptron': {\n",
    "        'model': Perceptron(max_iter=1000, random_state=seed),\n",
    "        'params': {'classifier__penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "                   'classifier__alpha': [0.0001, 0.001, 0.01]}\n",
    "    },\n",
    "\n",
    "    'SVM (RBF)': {\n",
    "        'model': SVC(kernel='rbf', probability=True, random_state=seed),\n",
    "        'params': {'classifier__C': [0.1, 1, 10]}\n",
    "        },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(eval_metric='logloss', random_state=seed),\n",
    "        'params': {\n",
    "            'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "            'classifier__max_depth': [3, 5, 7],\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "            'classifier__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    for smote_cenario in smote_cenarios:\n",
    "        smote_label = smote_cenario[\"label\"]\n",
    "        smote_config = smote_cenario[\"config\"]\n",
    "        print(f\"\\n Rodando protocolo para SMOTE: {smote_label}\")\n",
    "\n",
    "        for arquivo in arquivos:\n",
    "            print(f\"\\nRodando protocolo para o arquivo: {arquivo}\")\n",
    "            inicio_arquivo = time.time()\n",
    "\n",
    "            # Carregar o dataset\n",
    "            dataset = carregar_dataset(os.path.join(caminho_pasta, arquivo))\n",
    "            \n",
    "            # Definir colunas\n",
    "            target_column = 'target' \n",
    "            sensitive_col_name = 'sensitive_sexo'\n",
    "            print(\"Colunas identificadas como sensíveis:\", sensitive_col_name)\n",
    "            feature_columns = [col for col in dataset.columns if col not in [target_column]]\n",
    "\n",
    "            # Separar target, features\n",
    "            x = dataset[feature_columns]\n",
    "            y = dataset[target_column]\n",
    "\n",
    "            # Cenário 1: Com variáveis sensíveis\n",
    "            x_with_protected = x.copy()\n",
    "\n",
    "            # Cenário 2: Sem variáveis sensíveis\n",
    "            #x_without_protected = x.drop(columns=sensitive_col_name)\n",
    "\n",
    "            # Divisão entre treino e teste para ambos os cenários\n",
    "            cenarios = [\n",
    "                (x_with_protected, \"Com Variáveis Sensíveis\")\n",
    "            ]\n",
    "\n",
    "            resultados_completos = []\n",
    "            parametros_completos = []\n",
    "            importancia_variaveis = []\n",
    "            fairness_results = []\n",
    "            extended_fairness_results = []\n",
    "\n",
    "            # Loop pelos cenários\n",
    "            for x_data, label in cenarios:\n",
    "                print(f\"**Cenário: {label} | {smote_label}\")\n",
    "\n",
    "                grupo_focus = (\n",
    "                    (dataset['target'] == 1) &\n",
    "                    (dataset['sensitive_sexo'] == 'female') &\n",
    "                    (dataset['MARRIAGE'] == 'single') &\n",
    "                    (dataset['EDUCATION'] == 'high_school')).astype(int)\n",
    "\n",
    "                x_train, x_test, y_train, y_test, grupo_focus_train, grupo_focus_test = train_test_split(x_data, y, grupo_focus, test_size=0.3, stratify=y, random_state=seed)\n",
    "                \n",
    "                resultados, pipelines = treinar_e_ajustar_modelos_por_sensivel(x_train, y_train, grupo_focus_train, models, cv, smote_config, smote_label, label, arquivo)\n",
    "                \n",
    "                for modelo, pipeline in pipelines.items():\n",
    "                    print('Modelo:', modelo)\n",
    "                    y_pred_test = pipeline.predict(x_test)\n",
    "\n",
    "                    # Fairness para cada variável sensível\n",
    "                    sensitive_features = dataset[sensitive_col_name].iloc[x_test.index]\n",
    "                \n",
    "                    metrics = {\n",
    "                            'count': count,\n",
    "                            'accuracy': accuracy_score,\n",
    "                            'recall': recall_score,\n",
    "                            'precision': precision_score,\n",
    "                            'f1': f1_score,\n",
    "                            'confusion_matrix':confusion_matrix,\n",
    "                            'true_positive_rate': true_positive_rate,\n",
    "                            'true_negative_rate': true_negative_rate,\n",
    "                            'false_positive_rate': false_positive_rate,\n",
    "                            'false_negative_rate': false_negative_rate,\n",
    "                            'selection_rate':selection_rate}\n",
    "                    \n",
    "                    # Calcular métricas para cada variável sensível separadamente\n",
    "                    \n",
    "                    metric_frame = MetricFrame(\n",
    "                        metrics=metrics,\n",
    "                        y_true=y_test,\n",
    "                        y_pred=y_pred_test,\n",
    "                        sensitive_features=sensitive_features)\n",
    "                    \n",
    "                    for group in metric_frame.by_group.index:\n",
    "                        row = { \"dataset\": arquivo, \n",
    "                            \"cenario\": label,\n",
    "                            \"smote\": smote_label,\n",
    "                            \"modelo\": modelo, \n",
    "                            \"feature\": sensitive_col_name,\n",
    "                            \"group\": group\n",
    "                        }\n",
    "                        # Adicionar todas as métricas calculadas para o grupo\n",
    "                        for metric, values in metric_frame.by_group.items():\n",
    "                            row[metric] = values[group]\n",
    "                        fairness_results.append(row)\n",
    "                        \n",
    "                    # Métricas agrupasdas de fearness\n",
    "                    extended_fairness_metrics = extended_fairness(y_test, y_pred_test, sensitive_features)\n",
    "                    extended_fairness_results.append({\"dataset\": arquivo, \"cenario\": label, \"smote\": smote_label, \"modelo\": modelo, \"feature\": sensitive_col_name, **extended_fairness_metrics})\n",
    "\n",
    "                    # Resultados dos modelos \n",
    "                    try:\n",
    "                        y_prob = pipeline.predict_proba(x_test)[:, 1]\n",
    "                        auc = roc_auc_score(y_test, y_prob)\n",
    "                    except AttributeError:\n",
    "                        auc = None\n",
    "\n",
    "                    resultados_completos.append({\n",
    "                        \"modelo\": modelo,\n",
    "                        \"cenario\": label,\n",
    "                        \"smote\": smote_label,\n",
    "                        \"acuracia_teste\": accuracy_score(y_test, y_pred_test),\n",
    "                        \"recall_teste\": recall_score(y_test, y_pred_test),\n",
    "                        \"precisao_teste\": precision_score(y_test, y_pred_test),\n",
    "                        \"f1_teste\": f1_score(y_test, y_pred_test),\n",
    "                        \"auc_teste\": auc,\n",
    "                        \"classification_report_teste\": classification_report(y_test, y_pred_test, output_dict=True),\n",
    "                        \"confusion_matrix_teste\":confusion_matrix(y_test, y_pred_test, labels=[0, 1])\n",
    "                    })\n",
    "\n",
    "                    #Melhores parametros selecionados\n",
    "                    parametros_completos.append({\n",
    "                        \"modelo\": modelo,\n",
    "                        \"cenario\": label,\n",
    "                        \"smote\": smote_label,\n",
    "                        \"melhores_parametros\": pipelines[modelo].named_steps['classifier'].get_params()\n",
    "                    })\n",
    "\n",
    "                    # Calcular e armazenar importância das variáveis\n",
    "                    importancia_variaveis.extend(calcular_importancia_variaveis(pipeline, modelo, arquivo, f\"{label} | {smote_label}\", X_val=x_test, y_val=y_test))\n",
    "                    \n",
    "            # Salvar resultados por dataset\n",
    "            pd.DataFrame(resultados_completos).to_csv(os.path.join(results_path, f\"{arquivo}_{smote_label}_resultados_completos.csv\"), index=False)\n",
    "            pd.DataFrame(parametros_completos).to_csv(os.path.join(results_path, f\"{arquivo}_{smote_label}_parametros_completos.csv\"), index=False)\n",
    "            pd.DataFrame(importancia_variaveis).to_csv(os.path.join(results_path, f\"{arquivo}_{smote_label}_importancia_variaveis.csv\"), index=False)\n",
    "            pd.DataFrame(fairness_results).to_csv(os.path.join(results_path, f\"{arquivo}_{smote_label}_fairness_results.csv\"), index=False)\n",
    "            pd.DataFrame(extended_fairness_results).to_csv(os.path.join(results_path, f\"{arquivo}_{smote_label}_extended_fairness_results.csv\"), index=False)\n",
    "\n",
    "            fim_arquivo = time.time()\n",
    "            tempo_gasto = fim_arquivo - inicio_arquivo\n",
    "            print(f\"Tempo gasto no arquivo '{arquivo}': {tempo_gasto:.2f} segundos\")\n",
    "\n",
    "        print(\"\\nProtocolo concluído com sucesso!\")\n",
    "\n",
    "# Executar o protocolo na pasta\n",
    "executar_protocolo_com_cenarios(\"../datasets/processed\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fairness_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
